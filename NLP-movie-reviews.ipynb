{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "22e23ed59d4223e008ae704b0a73cc2c",
     "grade": false,
     "grade_id": "cell-6b464efd2fb5aabd",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Background & Work Flow\n",
    "\n",
    "- I will be analyzing text data. A common approach to analyzing text data is to use methods that allow us to convert text data into some kind of numerical representation - since we can then use all of our mathematical tools on such data. In this small project, I will explore 2 feature engineering methods that convert raw text data into numerical vectors:\n",
    "    - **Bag of Words (BoW)**\n",
    "        - BoW encodes an input sentence as the frequency of each word in the sentence. \n",
    "        - In this approach, all words contribute equally to the feature vectors.\n",
    "    - **Term Frequency - Inverse Document Frequency (TF-IDF)**\n",
    "        - TF-IDF is a measure of how important each term is to a specific document, as compared to an overall corpus. \n",
    "        - TF-IDF encodes each word as its frequency in the document of interest, divided by a measure of how common the word is across all documents (the corpus).\n",
    "        - Using this approach, each word contributes differently to the feature vectors.\n",
    "        - The assumption behind using TF-IDF is that words that appear commonly everywhere are not that informative about what is specifically interesting about a document of interest, so it is tuned to representing a document in terms of the words it uses that are different from other documents. \n",
    "\n",
    "- To compare those 2 methods, we will first apply them on the same Movie Review dataset to analyse sentiment (how positive or negative a text is). In order to make the comparison fair, an **SVM (support vector machine)** classifier will be used to classify positive reviews and negative reviews.\n",
    "\n",
    "- SVM is a simple yet powerful and interpretable linear model. To use it as a classifier, we need to have at least 2 splits of the data: training data and test data. The training data is used to tune the weight parameters in the SVM to learn an optimal way to classify the training data. We can then test this trained SVM classifier on the test data, to see how well it works on data that the classifier has not seen before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f63e1844f8a30eea74bd83c5f95d294",
     "grade": false,
     "grade_id": "Imports",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import nltk package \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5632b559471c292d87ec10648f5ba360",
     "grade": false,
     "grade_id": "cell-d96a6fcbdcbed177",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "For this project I will be using `nltk`: the Natural Language Toolkit.\n",
    "\n",
    "To do so, I will need to download some text data.\n",
    "\n",
    "Natural language processing (NLP) often requires corpus data (lists of words, and/or example text data) which is what I will download here now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f82bd6229164ec98da8b4dc9a3bf25e",
     "grade": false,
     "grade_id": "cell-04e576aebbcdfe34",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/crebollarramirez/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/crebollarramirez/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLTK English Tokenizer and stopwords of all languages\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "24a0b3abfec4714eceedc8a9d86532ad",
     "grade": false,
     "grade_id": "cell-c728326960d37d88",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Sentiment Analysis on Movie Review Data\n",
    "\n",
    "I will apply sentiment analysis to Movie Review (MR) data.\n",
    "\n",
    "- The MR data contains more than 10,000 reviews collected from the IMDB website, and each of the reviews is annotated as either positive or negative. The number of positive and negative reviews are roughly the same. For more information about the dataset, you can visit http://www.cs.cornell.edu/people/pabo/movie-review-data/\n",
    "\n",
    "- For this project, I already shuffled the data, and truncated the data to contain only 5000 reviews.\n",
    "\n",
    "Goals of this part of the project:\n",
    "- Transform the raw text data into vectors with the BoW encoding method\n",
    "- Split the data into training and test sets\n",
    "- Write a function to train an SVM classifier on the training set\n",
    "- Test this classifier on the test set and report the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8caa3884d098ea664567f93a5f9a79fa",
     "grade": false,
     "grade_id": "cell-7ae64525daa7892e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "88eedab80a7514a2ff88657341259940",
     "grade": false,
     "grade_id": "Q-1a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "MR_df = pd.read_csv('data/rt-polarity.tsv', sep='\\t', header=None)\n",
    "MR_df.rename(columns={1: 'label', 2: 'review'}, inplace=True)\n",
    "\n",
    "# Double Checking the data\n",
    "MR_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "46df931d2719a305a17d27032f9e8ecc",
     "grade": false,
     "grade_id": "cell-e58856b30bc3af1b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Function that converts string labels to numerical labels\n",
    "\n",
    "\n",
    "`convert_label` function features:\n",
    "- take two parameters `label` and `direction`\n",
    "- if `direction` is 'tonumber', \n",
    "    - and if the input label is \"pos\" return 1.0\n",
    "    - and if the input label is \"neg\" return 0.0\n",
    "    - otherwise, return the input label as is\n",
    "- if `direction` is 'tolabel'\n",
    "    - and if the input label is `1.0` return \"pos\"\n",
    "    - and if the input label is `0.0` return \"neg\"\n",
    "    - otherwise, return the label as is\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34df8e81740694660169c28ddbdc04ad",
     "grade": false,
     "grade_id": "Q-1b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def convert_label(label, direction):\n",
    "    if direction == 'tonumber':\n",
    "        if label == 'pos':\n",
    "            return 1.0\n",
    "        elif label == 'neg':\n",
    "            return 0.0\n",
    "        \n",
    "    elif direction == 'tolabel':\n",
    "        if label == 1.0:\n",
    "            return 'pos'\n",
    "        elif label == 0.0:\n",
    "            return 'neg'\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fb48a8d457203b9f076c9434f8dd02fc",
     "grade": false,
     "grade_id": "cell-55cca598b0986137",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Numerical Labels\n",
    "Converting all labels in `MR_df[\"label\"]` to numerical labels, using the `convert_label` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4daa25502cde5195c545154ed2009e33",
     "grade": false,
     "grade_id": "Q-1c",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8477</td>\n",
       "      <td>neg</td>\n",
       "      <td>except as an acting exercise or an exceptional...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4031</td>\n",
       "      <td>pos</td>\n",
       "      <td>japanese director shohei imamura 's latest fil...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10240</td>\n",
       "      <td>neg</td>\n",
       "      <td>i walked away not really know who `` they `` w...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8252</td>\n",
       "      <td>neg</td>\n",
       "      <td>what could have been a neat little story about...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1346</td>\n",
       "      <td>pos</td>\n",
       "      <td>no screen fantasy-adventure in recent memory h...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>1229</td>\n",
       "      <td>pos</td>\n",
       "      <td>pacino is brilliant as the sleep-deprived dorm...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>70</td>\n",
       "      <td>pos</td>\n",
       "      <td>a taut , intelligent psychological drama .</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>9832</td>\n",
       "      <td>neg</td>\n",
       "      <td>' . . . the cast portrays their cartoon counte...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>9140</td>\n",
       "      <td>neg</td>\n",
       "      <td>the central character is n't complex enough to...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>8507</td>\n",
       "      <td>neg</td>\n",
       "      <td>excruciatingly unfunny and pitifully unromantic .</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0 label                                             review    Y\n",
       "0      8477   neg  except as an acting exercise or an exceptional...  0.0\n",
       "1      4031   pos  japanese director shohei imamura 's latest fil...  1.0\n",
       "2     10240   neg  i walked away not really know who `` they `` w...  0.0\n",
       "3      8252   neg  what could have been a neat little story about...  0.0\n",
       "4      1346   pos  no screen fantasy-adventure in recent memory h...  1.0\n",
       "...     ...   ...                                                ...  ...\n",
       "4995   1229   pos  pacino is brilliant as the sleep-deprived dorm...  1.0\n",
       "4996     70   pos         a taut , intelligent psychological drama .  1.0\n",
       "4997   9832   neg  ' . . . the cast portrays their cartoon counte...  0.0\n",
       "4998   9140   neg  the central character is n't complex enough to...  0.0\n",
       "4999   8507   neg  excruciatingly unfunny and pitifully unromantic .  0.0\n",
       "\n",
       "[5000 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MR_df['Y'] = MR_df['label'].map(lambda x : convert_label(x, direction='tonumber'))\n",
    "MR_df\n",
    "\n",
    "# Verifying if everything is right\n",
    "MR_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "728136376a427b7c11e909560cd5da44",
     "grade": false,
     "grade_id": "cell-ec55be6eb56c03a9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Convert Text data into vector \n",
    "\n",
    "I will now create a `CountVectorizer` object to transform the text data into vectors with numerical values. \n",
    "\n",
    "To do so, I initialized a `CountVectorizer` object, and named it as `vectorizer`.\n",
    "\n",
    "I passed 4 arguments to initialize a CountVectorizer:\n",
    "  1. `analyzer`: `'word'` \n",
    "          Specify to analyze data from word-level.\n",
    "  2. `max_features`: `2000`\n",
    "          Set a max number of unique words.\n",
    "  3. `tokenizer`: `word_tokenize`\n",
    "          Set to tokenize the text data by using the word_tokenizer from NLTK .\n",
    "  4. `stop_words`: `stopwords.words('english')`\n",
    "          Set to remove all stopwords in English. We do this since they generally don't provide useful discriminative information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9a46f710926e62bd3c0bce5c787892c",
     "grade": false,
     "grade_id": "Q-1d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word', max_features=2000, tokenizer=word_tokenize, stop_words=stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bee6356add469699251cf94d38120bc6",
     "grade": false,
     "grade_id": "cell-a60876e4262f29a7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Vectorize reviews\n",
    "\n",
    "I transform reviews `MR_df[\"review\"]` into vectors using the `vectorizer` I created above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "40b2b185e93055aca4dbbcf0559f5feb",
     "grade": false,
     "grade_id": "Q-1e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "MR_X = vectorizer.fit_transform(MR_df[\"review\"]).toarray()\n",
    "MR_Y = np.array(MR_df['Y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ce0eb60471fe6db91fdc4328d4506e6",
     "grade": false,
     "grade_id": "cell-3b9ae1c6a8d22bfa",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Defining the train & test sets\n",
    "\n",
    "I will instead used `sklearn`'s `train_test_split()` function here to define our train and test set. I stored the train data (predictors) into `MR_train_X` and labels (outcomes) into `MR_train_Y`. Similarly, I stored the test data into `MR_test_X` and test labels into `MR_test_Y`.\n",
    "\n",
    "In addition to providing the predictors (`MR_X`) and outcomes (`MR_Y`) to the function, I used the following arguments for this task which is very important:\n",
    "- `test_size`: 0.2\n",
    "- `random_state`: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e298ab23819a9a4594044f2a0093de8d",
     "grade": false,
     "grade_id": "Q-1g",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "MR_train_X, MR_test_X, MR_train_Y, MR_test_Y = train_test_split(MR_X, MR_Y, test_size=0.2, random_state=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b09aa9ab50ccd1424ecdb8e6e7784336",
     "grade": false,
     "grade_id": "cell-4ee18efec80f9071",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### SVM\n",
    "\n",
    "Function `train_SVM` that initializes an SVM classifier and trains it\n",
    "\n",
    "Inputs: \n",
    "- `X`: np.ndarray, training samples, \n",
    "- `y`: np.ndarray, training labels,\n",
    "- `kernel`: string, set the default value of \"kernel\" as \"linear\"\n",
    "\n",
    "Output: a trained classifier `clf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5fbfdd5a9069ab146b47c82776b71e71",
     "grade": false,
     "grade_id": "Q-1i",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def train_SVM(X, y, kernel='linear'):\n",
    "    clf = SVC(kernel=kernel)\n",
    "    clf.fit(X,y)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a1f729a6afc885144548addafc634df4",
     "grade": false,
     "grade_id": "cell-f6a7b7746e81a1e8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Train SVM\n",
    "\n",
    "Trained an SVM classifier with the default linear kernel on the samples `MR_train_X` and the labels `MR_train_Y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "045b0b73c674e9ea174a52a6159cd14d",
     "grade": false,
     "grade_id": "Q-ij",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "MR_clf = train_SVM(MR_train_X, MR_train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "591492a7b4dfa7ae9f7b38c77828c086",
     "grade": false,
     "grade_id": "cell-d3f56db518a7fe0b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Predict outcome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "92659f65db8bb439049106ef91a1de1b",
     "grade": false,
     "grade_id": "Q-k",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "MR_predicted_train_Y = MR_clf.predict(MR_train_X)\n",
    "MR_predicted_test_Y = MR_clf.predict(MR_test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "803b99a1647d3f2fcc48e6dddecb55e2",
     "grade": false,
     "grade_id": "cell-020455c9d9568651",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    " `classification_report` that prints out the perfornamce of the classifier on the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae017392de7bfa1b6edbc6c36384a835",
     "grade": false,
     "grade_id": "cell-fc5799e344e24b69",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Your classifier should be able to reach above 90% accuracy \n",
    "# on the training set\n",
    "print(classification_report(MR_train_Y,MR_predicted_train_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1cc7d4b45837fca1e3e0ec54d539d6cf",
     "grade": false,
     "grade_id": "cell-2671503286c309f6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Checking the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "746d7f5c221258f743d9a36cc421c8db",
     "grade": false,
     "grade_id": "cell-9fc925527bb32076",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Your classifier should be able to reach around 67% accuracy on the test set.\n",
    "print(classification_report(MR_test_Y, MR_predicted_test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4c5e1d70bacc6af5e15fa62063b46a21",
     "grade": false,
     "grade_id": "cell-1f649bb709859c3e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# TF-IDF \n",
    "\n",
    "I have explored TF-IDF on sentiment analysis.\n",
    "\n",
    "TF-IDF is used as an alternate way to encode text data, as compared to the BoW approach\n",
    "\n",
    "Goals for this part of the project\n",
    "- Transform the raw text data into vectors using TF-IDF\n",
    "- Train an SVM classifier on the training set and report the performance this classifer on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d721619e0c0f589b1779dd89cd3e76a5",
     "grade": false,
     "grade_id": "cell-247ceced075ac236",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Text Data to Vectors\n",
    "\n",
    "I created a `TfidfVectorizer` object to transform the text data into vectors with TF-IDF\n",
    "\n",
    "\n",
    "Here are the arguments. \n",
    "  1. `sublinear_tf`: `True`\n",
    "           Set to apply TF scaling.\n",
    "  2. `analyzer`: `'word'`\n",
    "           Set to analyze the data at the word-level\n",
    "  3. `max_features`: `2000`\n",
    "           Set the max number of unique words\n",
    "  4. `tokenizer`: `word_tokenize`\n",
    "           Set to tokenize the text data by using the word_tokenizer from NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "baa7e33497e93c23af953771df844c8c",
     "grade": false,
     "grade_id": "Q-2a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, analyzer='word', max_features=2000, tokenizer=word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0facce13b1eb7a65aed335192a80cf05",
     "grade": false,
     "grade_id": "cell-ffac7f563014d29e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Transform Reviews \n",
    "\n",
    "I have transformed the `review` column of `MR_df` into vectors using the `tfidf` I have created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "025ea6833ba6f4df312c31deaa497e2d",
     "grade": false,
     "grade_id": "Q-2b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "tfidf.fit(MR_df['review'])\n",
    "MR_tfidf_X = tfidf.transform(MR_df['review']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cc30f84f103aeeb6b9c3b77ec64f83d3",
     "grade": false,
     "grade_id": "cell-b9b4c5df67dcdaad",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Using `train_test_split`, I split the `MR_tfidf_X` and `MR_Y` into training set and test set. \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "591708dbcc5c302cd7676f072937d4e8",
     "grade": false,
     "grade_id": "Q-2c",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "MR_train_tfidf_X, MR_test_tfidf_X, MR_train_tfidf_Y, MR_test_tfidf_Y = train_test_split(\n",
    "    MR_tfidf_X, MR_Y, test_size=0.2, random_state=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "44d1ded926210c5b931ec4239b5f142b",
     "grade": false,
     "grade_id": "cell-96712af487883a5a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2d) Training\n",
    "\n",
    "I trained an SVM classifier on the samples `MR_train_tfidf_X` and the labels `MR_train_tfidf_Y`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6eb6e10b5381e26bae6627ed77281b85",
     "grade": false,
     "grade_id": "Q-2d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "MR_tfidf_clf = train_SVM(MR_train_tfidf_X, MR_train_tfidf_Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "71c8a610918dac9b1ad345ce587a5556",
     "grade": false,
     "grade_id": "cell-e495a3fb363f328e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "816245b11f565460b7f1b8bff30b150d",
     "grade": false,
     "grade_id": "Q-2e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "MR_pred_train_tfidf_Y = MR_tfidf_clf.predict(MR_train_tfidf_X)\n",
    "\n",
    "MR_pred_test_tfidf_Y = MR_tfidf_clf.predict(MR_test_tfidf_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2493c1aedb1e3ab34d4be8d274aae56f",
     "grade": false,
     "grade_id": "cell-1a135f4081b1600b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Again, I used `classification_report` to check the performance on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9aa9ef44bf308106a5011ad8a9dcbce",
     "grade": false,
     "grade_id": "cell-afa1a0e6e8f72a98",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(MR_train_tfidf_Y, MR_pred_train_tfidf_Y))\n",
    "\n",
    "# Again, I check the performance on the test set:\n",
    "print(classification_report(MR_test_tfidf_Y, MR_pred_test_tfidf_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "08de6639ca699e3ba9a4982afadb3769",
     "grade": false,
     "grade_id": "cell-15bf17c90c32702a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Sentiment Analysis on Customer Review with TF-IDF \n",
    "\n",
    "In this part of the project, I will use TF-IDF to analyse the sentiment of some Customer Review (CR) data.\n",
    "\n",
    "The CR data contains around 3771 reviews, and they were all collected from the Amazon website. The reviews are annotated by humans as either positive reviews or negative reviews. In this dataset, the 2 classes are not balanced, as there are twice as many positive reviews as negative reviews.\n",
    "\n",
    "For more information on this dataset, visit https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html\n",
    "\n",
    "I have already split the data into a training set and a test set, in which the training set has labels for the reviews, but the test set doesn't. \n",
    "\n",
    "The goal is to train an SVM classifier on the training set, and then predict pos/neg for each review in the test set.\n",
    "\n",
    "Goals for this part of the project.\n",
    "- Use the TF-IDF feature engineering method to encode the raw text data into vectors\n",
    "- Train an SVM classifier on the training set\n",
    "- Predict labels for the reviews in the test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9b41eb30ece7fa8f2e5faf053610ba5c",
     "grade": false,
     "grade_id": "cell-c78ab60b7a795fbc",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05b2c41ceda6b26f147032316d2eb49a",
     "grade": false,
     "grade_id": "Q-3a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "CR_train_file = 'data/custrev_train.tsv'\n",
    "CR_test_file = 'data/custrev_test.tsv'\n",
    "\n",
    "CR_train_df = pd.read_csv(CR_train_file, sep='\\t', names=['index', 'label', 'review'])\n",
    "CR_test_df = pd.read_csv(CR_test_file, sep='\\t', names=['index', 'review'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fa9021ff6835a50be2f6dcc66a772fd0",
     "grade": false,
     "grade_id": "cell-ddb99da35eff3818",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77cb9f91e11824e5f97cf895bdc4a1ae",
     "grade": false,
     "grade_id": "Q-3b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "CR_df = pd.concat([CR_train_df, CR_test_df], ignore_index=True)\n",
    "CR_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7b373c41460bda436fbdf19f1ef18137",
     "grade": false,
     "grade_id": "cell-090a84f5c2674b36",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Cleaning\n",
    "\n",
    "Converting all labels in `CR_df[\"label\"]` using the `convert_label` function created previously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0144c733efbb0bccdcff00556f828467",
     "grade": false,
     "grade_id": "Q-3c",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "CR_df['Y'] = CR_df['label'].map(lambda x : convert_label(x, direction='tonumber'))\n",
    "CR_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3ac76fd4d906498bb1e9ee6e97af1869",
     "grade": false,
     "grade_id": "cell-8fd126d314b8d681",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Using `tfidf`\n",
    "\n",
    "Transforming reviews `CR_df[\"review\"]` into vectors using the `tfidf` vectorizer I created previously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9b5a50a8bfd01d1a84335933c17e079",
     "grade": false,
     "grade_id": "Q-3d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "tfidf.fit(CR_df['review'])\n",
    "CR_tfidf_X = tfidf.transform(CR_df['review']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "89919d34ef6cfe5ba7617be087452caa",
     "grade": false,
     "grade_id": "cell-528cadc1a8580ba2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Here I will collect all training samples & numerical labels from `CR_tfidf_X`. This will extract all samples with labels from the dataframe:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51219653065b9a7a98a57d482c50b0d6",
     "grade": false,
     "grade_id": "get_data",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# To collect labels\n",
    "CR_train_X = CR_tfidf_X[~CR_df['Y'].isnull()]\n",
    "CR_train_Y = CR_df['Y'][~CR_df['Y'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "472449b49b38d3fa878aaa454948bb04",
     "grade": false,
     "grade_id": "cell-d8b7615b2d8506b3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### SVM \n",
    "Training an SVM classifier on the samples `CR_train_X` and the labels `CR_train_Y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d7b2307c4b5cb41d418554659d2ef781",
     "grade": false,
     "grade_id": "Q-3e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "CR_clf = train_SVM(CR_train_X, CR_train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "45902f94bbec69e9f6fa58adc7cc87a1",
     "grade": false,
     "grade_id": "cell-56e632c22794e853",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Predict: training data\n",
    "\n",
    "Predicting labels on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a8514b0192f4492cf745a2884bb50f09",
     "grade": false,
     "grade_id": "Q-3f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "CR_pred_train_Y = CR_clf.predict(CR_train_X)\n",
    "#MR_pred_train_tfidf_Y = MR_tfidf_clf.predict(MR_train_tfidf_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "795c47b3e2ba4e0e9bb0fa9b7b2535fd",
     "grade": false,
     "grade_id": "cell-5393293deccc9d78",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Checking the classifier accuracy on the train data\n",
    "print(classification_report(CR_train_Y, CR_pred_train_Y))\n",
    "\n",
    "# Collecting all test samples from CR_tfidf_X\n",
    "CR_test_X = CR_tfidf_X[CR_df['Y'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "71f19c85cf12f1d2440eb513e910856e",
     "grade": false,
     "grade_id": "cell-7c227f5d7445fcdf",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Predict: test set\n",
    "Predicting the labels on the test set. I stored the predictions in a pandas DataFrame called `CR_pred_test_Y`, with the numeric predictions in a column (series) `'label'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89b10231bb5f2120e5665c31ae3f2e73",
     "grade": false,
     "grade_id": "cell-b6603f47310799dc",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "CR_pred_test_Y = pd.DataFrame(CR_clf.predict(CR_test_X), columns=['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "beef5263e50b8f7e8deda33d27ecd5c3",
     "grade": false,
     "grade_id": "cell-f91666d22c0dac60",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Convert labels\n",
    "\n",
    "Using the `convert_label` function, I converted the predicted numerical labels back to string labels (\"pos\" and \"neg\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dffb957468c0c3f47c0d9ad1d4043078",
     "grade": false,
     "grade_id": "Q-3h",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "CR_test_df['label'] = CR_pred_test_Y['label']\n",
    "CR_test_df['label'] = CR_test_df['label'].map(lambda x : convert_label(x, direction='tolabel'))\n",
    "\n",
    "# Now we have a dataset with the labels that were predicted using the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
